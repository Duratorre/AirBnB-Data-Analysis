{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's import all the necessary libraries first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Duratorre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Duratorre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Duratorre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "C:\\Users\\Duratorre\\Desktop\\DataScience_projects\\Nanodegree\\AirBnB Data\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import datetime\n",
    "import re\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "print(os.getcwd())\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>date</th>\n",
       "      <th>available</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12147973</td>\n",
       "      <td>2017-09-05</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12147973</td>\n",
       "      <td>2017-09-04</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12147973</td>\n",
       "      <td>2017-09-03</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12147973</td>\n",
       "      <td>2017-09-02</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12147973</td>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id        date available price\n",
       "0    12147973  2017-09-05         f   NaN\n",
       "1    12147973  2017-09-04         f   NaN\n",
       "2    12147973  2017-09-03         f   NaN\n",
       "3    12147973  2017-09-02         f   NaN\n",
       "4    12147973  2017-09-01         f   NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the datasets\n",
    "df_cal_sea = pd.read_csv('.\\Seattle\\calendar.csv')\n",
    "df_cal_sea.head(20)\n",
    "\n",
    "df_cal_bos = pd.read_csv('.\\Boston\\calendar.csv')\n",
    "df_cal_bos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Duratorre\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\Duratorre\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Duratorre\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Duratorre\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>price</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>241032</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>241032</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>241032</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>241032</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>241032</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    listing_id  price  month\n",
       "0       241032   85.0      1\n",
       "1       241032   85.0      1\n",
       "9       241032   85.0      1\n",
       "10      241032   85.0      1\n",
       "14      241032   85.0      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop rows with nan price and formatting data\n",
    "def format_calendar(df):\n",
    "    '''\n",
    "    This function takes as input a dataframe originated by reading in the calendar.csv files, and formats it to make it\n",
    "    ready to use for analysis on monthly, adding a column for the month, obtained by the date, and removing nans from the price\n",
    "    column\n",
    "    \n",
    "    Input:\n",
    "    df - a pandas dataframe obtained by reading in the calendar.csv files\n",
    "    \n",
    "    Output:\n",
    "    df_new - a pandas dataframe containing all the pertaining information for the analyis\n",
    "    '''\n",
    "        \n",
    "    df_new = df.dropna(subset=['price'])\n",
    "    df_new['price'] = df['price'].str.replace('$','')\n",
    "    df_new['price'] = df_new['price'].str.replace(',','').astype(float)\n",
    "    df_new['month'] = pd.to_datetime(df_new['date']).dt.month\n",
    "    df_new.drop(columns=['date', 'available'], inplace=True)\n",
    "\n",
    "    return df_new\n",
    "\n",
    "df_cal_sea_form = format_calendar(df_cal_sea)\n",
    "df_cal_bos_form = format_calendar(df_cal_bos)\n",
    "\n",
    "df_cal_sea_form.head()\n",
    "\n",
    "#df_cal2 = df_cal[df_cal.loc[:,'available']=='t']\n",
    "#df_cal2['price'] = df_cal2['price'].str.replace('$','')\n",
    "#df_cal2['price'] = df_cal2['price'].str.replace(',','').astype(float)\n",
    "#df_cal2['month'] = pd.to_datetime(df_cal2['date']).dt.month\n",
    "#df_cal2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unneccesary columns\n",
    "#df_cal3 = df_cal2.drop(columns=['date', 'available'])\n",
    "#df_cal3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# obtain the months where prices are lower and higher for the two cities\n",
    "def get_extremes(df, values, index, columns, aggfunc):\n",
    "    '''\n",
    "    This function creates a pivot table out of a dataframe and add columns \"max\" and \"min\" to the existing dataframe\n",
    "    containing respectively the column labels with the highest and lowest values\n",
    "    \n",
    "    Input:\n",
    "    df - a pandas dataframe that needs to be transformed into a pivot table\n",
    "    values - a pandas dataframe column label that will be the aggregate value of the pivot\n",
    "    index - a pandas dataframe column label that will be the rows of the pivot\n",
    "    columns - a pandas dataframe column label that will be the columns of the pivot\n",
    "    aggfunc - a function for aggregating the values\n",
    "    \n",
    "    Output:\n",
    "    df_pivot - a pandas dataframe transformed into a pivot and with a \"max\" column for the maximum value among \n",
    "    existing columns\n",
    "    '''\n",
    "    \n",
    "    df_pivot = df.pivot_table(values=values, index=index, columns=columns, aggfunc=aggfunc).reset_index()\n",
    "    df_pivot['max'] = df_pivot.drop(columns=df_pivot.columns[0]).idxmax(axis=1, skipna=True)\n",
    "    df_pivot['min'] = df_pivot.drop(columns=[df_pivot.columns[0], df_pivot.columns[-1]]).idxmin(axis=1, skipna=True)\n",
    "    df_pivot.columns.name = None\n",
    "    \n",
    "    for month in range(len(df_pivot['max'])):\n",
    "        if df_pivot['max'][month]==1:\n",
    "            if df_pivot[1][month]==df_pivot.drop(columns=[df_pivot.columns[0],df_pivot.columns[-1],df_pivot.columns[-2]]).loc[month].mean():\n",
    "                df_pivot['max'][month]=np.nan\n",
    "                df_pivot['min'][month]=np.nan\n",
    "                \n",
    "    return df_pivot\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Duratorre\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Duratorre\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "df_cal_sea_ext = get_extremes(df_cal_sea_form, values='price', index='listing_id', columns='month', aggfunc=np.nanmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Duratorre\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Duratorre\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "df_cal_bos_ext = get_extremes(df_cal_bos_form, values='price', index='listing_id', columns='month', aggfunc=np.nanmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best month to rent an airbnb is 4.0, while the worst month is 1.0\n",
      "The best month to rent an airbnb is 10.0, while the worst month is 1.0\n"
     ]
    }
   ],
   "source": [
    "# get the best and worst month to rent an airbnb\n",
    "best_sea = df_cal_sea_ext['max'].mode()\n",
    "worst_sea = df_cal_sea_ext['min'].mode()\n",
    "\n",
    "best_bos = df_cal_bos_ext['max'].mode()\n",
    "worst_bos = df_cal_bos_ext['min'].mode()\n",
    "\n",
    "#count = (df_cal_sea_ext['min'] == 1).sum()/df_cal_sea_ext['min'].size\n",
    "#count\n",
    "#best.values[0], worst.values[0]\n",
    "print('The best month to rent an airbnb is {}, while the worst month is {}'.format(best_sea.values[0], worst_sea.values[0]))\n",
    "print('The best month to rent an airbnb is {}, while the worst month is {}'.format(best_bos.values[0], worst_bos.values[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29626645178619393"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count = (df_cal_sea_ext['min'] == 1).sum()/df_cal_sea_ext['min'].size\n",
    "#count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_lis = pd.read_csv('.\\Seattle\\listings.csv')\n",
    "df_lis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_lis.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all columns with url\n",
    "df_lis = df_lis.loc[:,~df_lis.columns.str.contains('url', case = False)]\n",
    "df_lis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns with unique values\n",
    "unique_values = []\n",
    "for col in list(df_lis.columns):\n",
    "    if df_lis[col].unique().size==1:\n",
    "        unique_values.append(col)\n",
    "    \n",
    "print(unique_values)\n",
    "\n",
    "df_lis_no_unique = df_lis.drop(columns=unique_values)\n",
    "df_lis_no_unique.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unnecessary columns\n",
    "unnec_col = ['name', \n",
    "             'host_id', 'host_name', 'host_since', 'host_location', 'host_about', 'host_neighbourhood', \n",
    "             'neighborhood_overview', 'notes', 'street', 'neighbourhood_cleansed', 'neighbourhood_group_cleansed', \n",
    "             'city', 'state', 'zipcode', 'smart_location', 'latitude', 'longitude', 'weekly_price', 'monthly_price',\n",
    "             'calendar_updated', 'availability_30', 'availability_60', 'availability_90', 'availability_365', 'first_review',\n",
    "             'last_review', 'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin',\n",
    "             'review_scores_communication', 'review_scores_location', 'review_scores_value']\n",
    "\n",
    "\n",
    "df_lis_no_unn = df_lis_no_unique.drop(columns=unnec_col)\n",
    "df_lis_no_unn.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_lis_no_unn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing unnecessary columns and dealing with nan\n",
    "df_lis2 = df_lis_no_unn.drop(columns=['summary', 'space', 'description'])\n",
    "df_lis2.head()\n",
    "\n",
    "df_lis2.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping columns with no relevance for ratings, as well as columns with majority on nan values, like \n",
    "df_lis3 = df_lis2.drop(columns=['host_acceptance_rate', 'square_feet'])\n",
    "\n",
    "# dropping rows with no ratings, as we can't perform correlation on those values\n",
    "df_lis4 = df_lis3.dropna(axis=0, how='any', subset=['review_scores_rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lis4.head()\n",
    "df_lis4.isna().mean()\n",
    "#df_lis9.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#df_lis5 = df_lis4.drop(columns = ['review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin',\n",
    "#                                  'review_scores_communication', 'review_scores_location', 'review_scores_value'])\n",
    "#df_lis_clean.isna().mean()\n",
    "#df_lis5.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_lis5 = df_lis4[~df_lis4['host_response_rate'].isnull()]\n",
    "df_lis5.isna().mean()\n",
    "df_lis5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# casting columns to their proper data types\n",
    "\n",
    "# % host_response_rate, \n",
    "#t & f host_is_superhost, host_has_profile_pic, host_identity_verified, is_location_exact, instant_bookable, require_guest_profile_picture, require_guest_phone_verification\n",
    "# $ price, security_deposit, extra_people\n",
    "#df_lis6.loc[:,'host_reponse_rate'] = df_lis6['host_response_rate'].str.replace('%', '').astype(float)\n",
    "df_lis5['host_response_rate'] = df_lis5['host_response_rate'].str.replace('%', '').astype(float)\n",
    "df_lis5.replace('t', 1, inplace=True)\n",
    "df_lis5.replace('f', 0, inplace=True)\n",
    "df_lis5['price'] = df_lis5['price'].str.replace('$', '').astype(float)\n",
    "df_lis5['security_deposit'] = df_lis5['security_deposit'].str.replace('$', '')\n",
    "df_lis5['security_deposit'] = df_lis5['security_deposit'].str.replace(',', '').astype(float)\n",
    "df_lis5['cleaning_fee'] = df_lis5['cleaning_fee'].str.replace('$', '').astype(float)\n",
    "df_lis5['extra_people'] = df_lis5['extra_people'].str.replace('$', '').astype(float)\n",
    "\n",
    "df_lis5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_lis_onlyr = df_lis[~df_lis['host_response_rate'].isnull()]\n",
    "#print(df_lis_onlyr.shape, len(df_lis_onlyr.host_id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dealing with NaNs\n",
    "# listing without bathrooms are all entire house/apartment or private rooms. We assume that in each of these accomodations there is at least one bathroom.\n",
    "# hosts with no response rate haw few listings. Since we want to incllude this feature in the analysis, we will remove those rows where the reposnse rste is null\n",
    "\n",
    "# neighborhood_overview, notes and host_about to be dropped. Security deposit and cleaning fee to be filled with 0. Review_scores_something to be dropped.\n",
    "\n",
    "df_lis5['bedrooms'].fillna(0, inplace=True) # as there can be homes w/o bedrooms\n",
    "df_lis5['bathrooms'].fillna(1, inplace=True) # all houses are entire building apartments or single rooms, there has to be a bathroom\n",
    "df_lis5['security_deposit'].fillna(0, inplace=True)\n",
    "df_lis5['cleaning_fee'].fillna(0, inplace=True)\n",
    "df_lis5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lis5.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(df, column_name):\n",
    "    '''\n",
    "    This function reproduces one hot encoding for those columns of a pandas dataframe that have a set or list of values \n",
    "    in each row\n",
    "    \n",
    "    Input:\n",
    "    df - a pandas dataframe \n",
    "    column_name - the column whose values are sets or lists\n",
    "    \n",
    "    Output:\n",
    "    new_df - a dataframe with one hot encoding for the selected column\n",
    "    '''\n",
    "    \n",
    "    # create a set of the distinct values contained in df[column_name]\n",
    "    item_set = set()\n",
    "    for item in df[column_name]:\n",
    "        #item = item.strip('{}')\n",
    "        #item = item.strip('[]')\n",
    "        #item = item.replace(' ', '')\n",
    "        #item = item.replace(\"'\", \"\")\n",
    "        #item = item.replace('''\"''', '')\n",
    "        item = re.sub(r\"[^a-zA-Z0-9\\,\\/\\-]\", \"\", item)\n",
    "        item = item.split(',')\n",
    "        new_entry = set(item)\n",
    "        item_set.update(new_entry)\n",
    "    \n",
    "    # remove any white spaces or None\n",
    "    try:\n",
    "        item_set.remove('')\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        item_set.remove('None')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # one hot encoding of df[column_name]\n",
    "    for item in list(item_set):  #[:-1]:\n",
    "        booleans = df[column_name].str.contains(item)\n",
    "        new_col = [int(boolean) for boolean in booleans]\n",
    "        new_col_name = '{}_{}'.format(column_name, item)\n",
    "        df[new_col_name] = new_col\n",
    "        \n",
    "    # remove original column from dataframe df\n",
    "    new_df = df.drop(columns = column_name)\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting features from categorical columns\n",
    "\n",
    "df_lis6 = extract_features(df_lis5, 'amenities')\n",
    "df_lis7 = extract_features(df_lis6, 'host_verifications')\n",
    "\n",
    "one_hot_columns = ['host_response_time', 'neighbourhood', 'property_type', 'room_type', 'bed_type', 'cancellation_policy']\n",
    "df_lis8 = pd.get_dummies(data = df_lis7, columns = one_hot_columns)  #, drop_first=True)\n",
    "df_lis8.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# One Hot Encoding for transportation\n",
    "\n",
    "transport_means = ['Bus', 'Light Rail', 'Ferry', 'Heavy Rail', 'Train', 'Metro', 'NaN']\n",
    "\n",
    "df_lis8['transit'].fillna(\"NaN\", inplace=True)\n",
    "\n",
    "for mean in transport_means:  #[:-1]:\n",
    "    booleans = df_lis8['transit'].str.contains(mean, False)    #re.find(mean, 'hello', re.IGNORECASE)\n",
    "    new_col = [int(boolean) for boolean in booleans]\n",
    "    new_col_name = 'transit_{}'.format(mean)\n",
    "    df_lis8[new_col_name] = new_col\n",
    "\n",
    "df_lis8.drop(columns='transit', inplace=True)\n",
    "df_lis8.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lis9 = df_lis8.drop(columns='id')\n",
    "df_lis9.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_lis9.corr()\n",
    "#corr\n",
    "corr.unstack()['price'].dropna().sort_values(ascending=False)\n",
    "\n",
    "#fig, ax = plt.subplots(figsize=(40,40))         # Sample figsize in inches\n",
    "#sns.heatmap(corr, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression\n",
    "X = df_lis9.drop(columns='price')\n",
    "y = df_lis9.price\n",
    "\n",
    "#split the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#fit the model and obtain pred response\n",
    "lm_model = LinearRegression(normalize=True)\n",
    "lm_model.fit(X_train, y_train)\n",
    "y_pred = lm_model.predict(X_test)\n",
    "#y_train_preds = lm_model.predict(X_train)\n",
    "\n",
    "#append the r2 value from the test set\n",
    "r2_score(y_test, y_pred)\n",
    "#r2_scores_test.append(r2_score(y_test, y_test_preds))\n",
    "#r2_scores_train.append(r2_score(y_train, y_train_preds))\n",
    "#results[str(cutoff)] = r2_score(y_test, y_test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred_log = log_reg.predict(X_test)\n",
    "\n",
    "r2_score(y_test, y_pred_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using support vector machines\n",
    "regr = svm.SVR()\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svm = regr.predict(X_test)\n",
    "r2_score(y_test, y_pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using random forest classifier\n",
    "rfr = RandomForestRegressor(n_estimators=300)\n",
    "rfr.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rfr = rfr.predict(X_test)\n",
    "r2_score(y_test, y_pred_rfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lis['review_scores_rating'].unique()\n",
    "df_lis_sort_values = df_lis.sort_values(by='review_scores_rating')\n",
    "df_lis_sort_values.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rev = pd.read_csv(\".\\\\Seattle\\\\reviews.csv\")\n",
    "df_rev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rev[df_rev['listing_id'] == 7202016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_rev.listing_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_lis.id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_lis[df_lis['number_of_reviews'] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lis[['neighbourhood', 'neighbourhood_group_cleansed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
